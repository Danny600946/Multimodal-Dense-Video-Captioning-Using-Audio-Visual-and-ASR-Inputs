# Multimodal-Dense-Video-Captioning-Using-Audio-Visual-and-ASR-Inputs
This dissertation explores enhancing dense video captioning by integrating audio into the Vid2Seq pipeline. By leveraging multimodal data, the project aims to improve caption accuracy and context, investigating the potential of audio-visual fusion for richer, more informative video descriptions.
